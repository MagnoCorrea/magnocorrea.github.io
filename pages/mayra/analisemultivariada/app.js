/**
 * App.js - Aplica√ß√£o Principal
 * Controla o fluxo da aplica√ß√£o e intera√ß√µes do usu√°rio
 */

let analyzer = null;
let visualizer = null;
let rawData = null;

// Elementos DOM
const fileInput = document.getElementById('csvFile');
const analyzeButton = document.getElementById('analyzeButton');
const uploadSection = document.getElementById('uploadSection');
const progressSection = document.getElementById('progressSection');
const resultsSection = document.getElementById('resultsSection');
const progressFill = document.getElementById('progressFill');
const progressText = document.getElementById('progressText');
const fileName = document.getElementById('fileName');

// Event Listeners
fileInput.addEventListener('change', handleFileSelect);
analyzeButton.addEventListener('click', startAnalysis);

// Tabs
const tabButtons = document.querySelectorAll('.tab-button');
tabButtons.forEach(button => {
    button.addEventListener('click', () => switchTab(button.dataset.tab));
});

// Export buttons
document.getElementById('exportHTML').addEventListener('click', exportHTML);
document.getElementById('exportCorrelation').addEventListener('click', exportCorrelation);
document.getElementById('exportClusters').addEventListener('click', exportClusters);
document.getElementById('exportJSON').addEventListener('click', exportJSON);

// Manipula√ß√£o de arquivo
function handleFileSelect(event) {
    const file = event.target.files[0];
    if (file) {
        fileName.textContent = `Arquivo selecionado: ${file.name}`;
        analyzeButton.style.display = 'block';
        
        // Ler arquivo CSV
        Papa.parse(file, {
            header: true,
            delimiter: ';',
            encoding: 'UTF-8',
            complete: (results) => {
                rawData = results.data.filter(row => {
                    return Object.values(row).some(val => val !== null && val !== '');
                });
                console.log('Dados carregados:', rawData.length, 'linhas');
            },
            error: (error) => {
                alert('Erro ao ler o arquivo: ' + error.message);
            }
        });
    }
}

// Iniciar an√°lise
async function startAnalysis() {
    if (!rawData || rawData.length === 0) {
        alert('Por favor, carregue um arquivo CSV v√°lido primeiro.');
        return;
    }
    
    // Mostrar se√ß√£o de progresso
    uploadSection.style.display = 'none';
    progressSection.style.display = 'block';
    
    try {
        // Inicializar analisador
        updateProgress(10, 'Inicializando an√°lise...');
        analyzer = new MultivariateAnalyzer(rawData);
        
        // Codificar dados
        updateProgress(20, 'Codificando dados categ√≥ricos...');
        await sleep(300);
        analyzer.encodeData();
        
        // An√°lise de correla√ß√£o
        updateProgress(35, 'Calculando matriz de correla√ß√£o...');
        await sleep(300);
        analyzer.calculateCorrelationMatrix();
        
        // PCA
        updateProgress(50, 'Realizando an√°lise PCA...');
        await sleep(300);
        analyzer.performPCA();
        
        // Clustering - M√©todo do Cotovelo
        updateProgress(65, 'Calculando m√©todo do cotovelo...');
        await sleep(300);
        const elbowData = analyzer.elbowMethod(10);
        
        // K-Means
        updateProgress(70, 'Executando K-Means clustering...');
        await sleep(300);
        analyzer.performKMeans(4);
        
        // t-SNE
        updateProgress(75, 'Realizando an√°lise t-SNE...');
        await sleep(300);
        const tsneResults = analyzer.performTSNE(30, 1000, 200);
        console.log('t-SNE Results:', tsneResults);
        
        // Clustering Hier√°rquico
        updateProgress(82, 'Calculando clustering hier√°rquico...');
        await sleep(300);
        const hierarchicalResults = analyzer.performHierarchicalClustering();
        console.log('Hierarchical Results:', hierarchicalResults);
        
        // Chi-quadrado
        updateProgress(88, 'Executando testes Chi-quadrado...');
        await sleep(300);
        const chiSquareResults = analyzer.performChiSquareAnalysis();
        
        // Caracterizar clusters
        updateProgress(93, 'Caracterizando clusters...');
        await sleep(300);
        const clusterProfiles = analyzer.characterizeClusters();
        
        // Criar visualiza√ß√µes
        updateProgress(97, 'Gerando visualiza√ß√µes...');
        await sleep(300);
        visualizer = new DataVisualizer(analyzer);
        renderAllVisualizations(clusterProfiles, elbowData, tsneResults, hierarchicalResults, chiSquareResults);
        
        // Mostrar resultados
        updateProgress(100, 'An√°lise conclu√≠da!');
        await sleep(500);
        
        progressSection.style.display = 'none';
        resultsSection.style.display = 'block';
        
    } catch (error) {
        console.error('Erro durante an√°lise:', error);
        alert('Erro durante a an√°lise: ' + error.message);
        progressSection.style.display = 'none';
        uploadSection.style.display = 'block';
    }
}

// Atualizar barra de progresso
function updateProgress(percent, text) {
    progressFill.style.width = percent + '%';
    progressText.textContent = text;
}

// Sleep helper
function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}

// Trocar tab
function switchTab(tabName) {
    // Remover active de todos
    document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
    document.querySelectorAll('.tab-panel').forEach(panel => panel.classList.remove('active'));
    
    // Adicionar active ao selecionado
    document.querySelector(`[data-tab="${tabName}"]`).classList.add('active');
    document.getElementById(`${tabName}Tab`).classList.add('active');
}

// Renderizar todas as visualiza√ß√µes
function renderAllVisualizations(clusterProfiles, elbowData, tsneResults, hierarchicalResults, chiSquareResults) {
    // Overview Tab
    renderOverviewTab();
    
    // Descriptive Tab
    renderDescriptiveTab();
    
    // Correlation Tab
    renderCorrelationTab();
    
    // PCA Tab
    renderPCATab();
    
    // Clustering Tab
    renderClusteringTab(clusterProfiles, elbowData, tsneResults, hierarchicalResults);
    
    // Profiles Tab
    renderProfilesTab(clusterProfiles, chiSquareResults);
    
    // Export Tab
    renderExportTab();
}

// Renderizar Overview Tab
function renderOverviewTab() {
    const totalResponses = analyzer.rawData.length;
    const totalQuestions = analyzer.columnNames.length;
    const completeness = 100; // Assumindo dados completos
    const clusters = analyzer.clusterResults.k;
    
    document.getElementById('totalResponses').textContent = totalResponses;
    document.getElementById('totalQuestions').textContent = totalQuestions;
    document.getElementById('completeness').textContent = completeness + '%';
    document.getElementById('clustersFound').textContent = clusters;
    
    // Data preview table
    renderDataPreview();
}

// Renderizar pr√©via dos dados com pagina√ß√£o
let currentPage = 1;
let rowsPerPage = 25;

function renderDataPreview() {
    const table = document.getElementById('dataPreviewTable');
    const headers = analyzer.columnNames;
    const totalRows = analyzer.rawData.length;
    const totalPages = Math.ceil(totalRows / rowsPerPage);
    
    // Garantir que currentPage est√° dentro dos limites
    if (currentPage > totalPages) currentPage = totalPages;
    if (currentPage < 1) currentPage = 1;
    
    const startIndex = (currentPage - 1) * rowsPerPage;
    const endIndex = Math.min(startIndex + rowsPerPage, totalRows);
    const rows = analyzer.rawData.slice(startIndex, endIndex);
    
    // Criar cabe√ßalho
    let html = '<thead><tr><th>#</th>';
    headers.forEach(h => {
        const shortHeader = h.length > 40 ? h.substring(0, 37) + '...' : h;
        html += `<th title="${h}">${shortHeader}</th>`;
    });
    html += '</tr></thead><tbody>';
    
    // Criar linhas
    rows.forEach((row, idx) => {
        html += `<tr><td>${startIndex + idx + 1}</td>`;
        headers.forEach(h => html += `<td>${row[h] || '-'}</td>`);
        html += '</tr>';
    });
    html += '</tbody>';
    
    table.innerHTML = html;
    
    // Atualizar controles de pagina√ß√£o
    document.getElementById('pageInfo').textContent = `P√°gina ${currentPage} de ${totalPages}`;
    document.getElementById('totalInfo').textContent = `Mostrando ${startIndex + 1}-${endIndex} de ${totalRows} registros`;
    document.getElementById('prevPage').disabled = currentPage === 1;
    document.getElementById('nextPage').disabled = currentPage === totalPages;
}

// Event listeners para pagina√ß√£o
document.getElementById('prevPage').addEventListener('click', () => {
    if (currentPage > 1) {
        currentPage--;
        renderDataPreview();
    }
});

document.getElementById('nextPage').addEventListener('click', () => {
    const totalPages = Math.ceil(analyzer.rawData.length / rowsPerPage);
    if (currentPage < totalPages) {
        currentPage++;
        renderDataPreview();
    }
});

document.getElementById('rowsPerPage').addEventListener('change', (e) => {
    rowsPerPage = parseInt(e.target.value);
    currentPage = 1; // Reset para primeira p√°gina
    renderDataPreview();
});

// Renderizar Descriptive Tab
function renderDescriptiveTab() {
    // === PERFIL DEMOGR√ÅFICO ===
    
    // Faixa Et√°ria
    const ageFreq = analyzer.getFrequencies('2 - Faixa et√°ria');
    visualizer.createBarChart('ageChart', {
        labels: ageFreq.map(f => f.value),
        values: ageFreq.map(f => f.count)
    }, 'Distribui√ß√£o por Faixa Et√°ria', true);
    
    // Pessoa com Defici√™ncia (n√£o existe G√™nero no CSV)
    const pcdFreq = analyzer.getFrequencies('1 - Voc√™ √© uma pessoa com defici√™ncia?');
    visualizer.createPieChart('genderChart', {
        labels: pcdFreq.map(f => f.value),
        values: pcdFreq.map(f => f.count)
    }, 'Pessoa com Defici√™ncia');
    
    // Escolaridade
    const eduFreq = analyzer.getFrequencies('3 - Escolaridade ');
    visualizer.createBarChart('educationChart', {
        labels: eduFreq.map(f => f.value),
        values: eduFreq.map(f => f.count)
    }, 'Distribui√ß√£o por Escolaridade', true);
    
    // √Årea de Atua√ß√£o
    const areaFreq = analyzer.getFrequencies('4 - √Årea de atua√ß√£o principal').slice(0, 10);
    visualizer.createBarChart('areaChart', {
        labels: areaFreq.map(f => f.value),
        values: areaFreq.map(f => f.count)
    }, 'Top 10 √Åreas de Atua√ß√£o', true);
    
    // === CONHECIMENTO E PR√ÅTICA ===
    
    // Uso de WCAG
    const wcagFreq = analyzer.getFrequencies('7 - Voc√™ utiliza as diretrizes do W3C/WCAG no seu trabalho?');
    visualizer.createPieChart('wcagChart', {
        labels: wcagFreq.map(f => f.value),
        values: wcagFreq.map(f => f.count)
    }, 'Uso de WCAG');
    
    // Aplica√ß√µes s√£o Acess√≠veis (n√£o existe pergunta sobre quantidade)
    const appsFreq = analyzer.getFrequencies('8 - Voc√™ acredita que as aplica√ß√µes desenvolvida por voc√™ ou pelo seu time s√£o acess√≠veis a pessoas com defici√™ncia?');
    visualizer.createPieChart('appsAccessibleChart', {
        labels: appsFreq.map(f => f.value),
        values: appsFreq.map(f => f.count)
    }, 'Apps Desenvolvidos s√£o Acess√≠veis?');
    
    // Sistemas da Empresa s√£o Acess√≠veis
    const knowledgeFreq = analyzer.getFrequencies('9 - Voc√™ acredita que os sistemas utilizados pela empresa onde voc√™ trabalha s√£o acess√≠veis √† pessoas com defici√™ncia? ');
    visualizer.createBarChart('knowledgeChart', {
        labels: knowledgeFreq.map(f => f.value),
        values: knowledgeFreq.map(f => f.count)
    }, 'Sistemas da Empresa s√£o Acess√≠veis?');
    
    // Preocupa√ß√£o
    const concernFreq = analyzer.getFrequencies('10 - Voc√™ ou seu time se preocupa com a acessibilidade (para pessoas com defici√™ncia) dos sistemas utilizados ou desenvolvidos? ').slice(0, 6);
    visualizer.createBarChart('concernChart', {
        labels: concernFreq.map(f => f.value),
        values: concernFreq.map(f => f.count)
    }, 'Preocupa√ß√£o com Acessibilidade');
    
    // Implementa√ß√£o
    const implFreq = analyzer.getFrequencies('11 - Voc√™ ou seu time implementa t√©cnicas de acessibilidade (para pessoas com defici√™ncia) durante a execu√ß√£o do projeto ou depois que o produto/sistema j√° est√° desenvolvido?');
    visualizer.createBarChart('implementationChart', {
        labels: implFreq.map(f => f.value),
        values: implFreq.map(f => f.count)
    }, 'Implementa√ß√£o de T√©cnicas');
    
    // Ferramentas de Valida√ß√£o (coluna 18)
    const toolsFreq = analyzer.getFrequencies('18  - Quais ferramentas de valida√ß√£o de pr√°ticas de acessibilidade Web voc√™ utiliza em seu trabalho? Escolha uma ou mais op√ß√µes ').slice(0, 8);
    visualizer.createBarChart('toolsChart', {
        labels: toolsFreq.map(f => f.value),
        values: toolsFreq.map(f => f.count)
    }, 'Ferramentas de Valida√ß√£o Utilizadas', true);
    
    // === EXPERI√äNCIA E DESAFIOS ===
    
    // Tempo de Fun√ß√£o (coluna 6)
    const expFreq = analyzer.getFrequencies('6 - H√° quanto tempo desenvolve sua fun√ß√£o? ');
    visualizer.createBarChart('experienceChart', {
        labels: expFreq.map(f => f.value),
        values: expFreq.map(f => f.count)
    }, 'Tempo de Experi√™ncia na Fun√ß√£o', true);
    
    // Motiva√ß√£o (coluna 14)
    const diffFreq = analyzer.getFrequencies('14 - No decorrer do desenvolvimento: qual motiva√ß√£o levaria voc√™ ou seu time  a utilizar ferramentas para garantir acessibilidade (para pessoas com defici√™ncia) nos sistemas desenvolvidos? Escolha uma ou mais op√ß√µes').slice(0, 8);
    visualizer.createBarChart('difficultiesChart', {
        labels: diffFreq.map(f => f.value),
        values: diffFreq.map(f => f.count)
    }, 'Motiva√ß√µes para Usar Ferramentas', true);
}

// Renderizar Correlation Tab
function renderCorrelationTab() {
    const correlationMatrix = analyzer.correlationMatrix;
    const labels = analyzer.columnNames;
    
    visualizer.createCorrelationMatrix('correlationMatrix', correlationMatrix, labels);
    
    // Top correlations table - Todas as correla√ß√µes (ordenadas por for√ßa)
    const allCorr = analyzer.getTopCorrelations(1000); // Pega todas as correla√ß√µes poss√≠veis
    const table = document.getElementById('topCorrelations');
    
    let html = '<thead><tr><th>#</th><th>Vari√°vel 1</th><th>Vari√°vel 2</th><th>Correla√ß√£o</th><th>For√ßa</th></tr></thead><tbody>';
    
    allCorr.forEach((corr, index) => {
        const strength = Math.abs(corr.correlation) > 0.5 ? 'Forte' : 
                        Math.abs(corr.correlation) > 0.3 ? 'Moderada' : 'Fraca';
        const color = Math.abs(corr.correlation) > 0.5 ? 'style="color: #10b981; font-weight: bold;"' :
                     Math.abs(corr.correlation) > 0.3 ? 'style="color: #f59e0b; font-weight: bold;"' : '';
        
        // Abreviar nomes das vari√°veis para melhor visualiza√ß√£o
        const var1Short = corr.var1.length > 50 ? corr.var1.substring(0, 47) + '...' : corr.var1;
        const var2Short = corr.var2.length > 50 ? corr.var2.substring(0, 47) + '...' : corr.var2;
        
        html += `<tr>
            <td>${index + 1}</td>
            <td title="${corr.var1}">${var1Short}</td>
            <td title="${corr.var2}">${var2Short}</td>
            <td ${color}>${corr.correlation.toFixed(3)}</td>
            <td>${strength}</td>
        </tr>`;
    });
    
    html += '</tbody>';
    table.innerHTML = html;
}

// Renderizar PCA Tab
function renderPCATab() {
    const pca = analyzer.pcaResults;
    
    visualizer.createScreePlot('screePlot', pca.explainedVariance);
    visualizer.createCumulativeVariancePlot('cumulativeVariance', pca.cumulativeVariance);
    visualizer.createPCABiplot('pcaBiplot', pca.projectedData, pca.loadings, analyzer.columnNames);
    
    // PCA Summary
    const summary = document.getElementById('pcaSummary');
    let html = '';
    
    pca.explainedVariance.slice(0, 5).forEach((variance, idx) => {
        html += `<div class="pca-component">
            <h4>Componente Principal ${idx + 1}</h4>
            <p><strong>Vari√¢ncia Explicada:</strong> ${(variance * 100).toFixed(2)}%</p>
            <p><strong>Vari√¢ncia Acumulada:</strong> ${(pca.cumulativeVariance[idx] * 100).toFixed(2)}%</p>
        </div>`;
    });
    
    summary.innerHTML = html;
}

// Renderizar Clustering Tab
function renderClusteringTab(clusterProfiles, elbowData, tsneResults, hierarchicalResults) {
    visualizer.createElbowPlot('elbowChart', elbowData);
    visualizer.createClusterDistribution('clusterDistribution', analyzer.clusterResults.clusters);
    visualizer.createClusterVisualization('clusterVisualization', 
        analyzer.pcaResults.projectedData, 
        analyzer.clusterResults.clusters);
    
    // t-SNE visualizations
    console.log('Rendering t-SNE with results:', tsneResults);
    if (tsneResults && tsneResults.Y) {
        console.log('t-SNE Y data points:', tsneResults.Y.length);
        visualizer.createTSNEVisualization('tsneChart', tsneResults.Y, 't-SNE: Redu√ß√£o de Dimensionalidade N√£o-Linear');
        visualizer.createTSNEWithClusters('tsneClusterChart', tsneResults.Y, analyzer.clusterResults.clusters);
    } else {
        console.error('t-SNE results are invalid:', tsneResults);
    }
    
    // Hierarchical clustering
    console.log('Rendering Hierarchical Clustering with results:', hierarchicalResults);
    if (hierarchicalResults && hierarchicalResults.dendrogramData) {
        console.log('Dendrogram data found:', hierarchicalResults.dendrogramData);
        visualizer.createDendrogram('dendrogramChart', hierarchicalResults.dendrogramData);
        visualizer.createHierarchyStructure('hierarchyChart', hierarchicalResults.dendrogramData, 4);
    } else {
        console.error('Hierarchical results are invalid:', hierarchicalResults);
    }
    
    // Cluster Profiles
    const profilesDiv = document.getElementById('clusterProfiles');
    let html = '';
    
    clusterProfiles.forEach(profile => {
        const clusterNames = ['Baixo Engajamento', 'Engajados', 'Designers Conscientes', 'Caso Especial'];
        const clusterDescriptions = [
            'Grupo com pouco conhecimento e baixa implementa√ß√£o de acessibilidade',
            'Profissionais com alto conhecimento e implementa√ß√£o consistente',
            'Profissionais com conhecimento moderado focados em design',
            'Perfil at√≠pico que requer investiga√ß√£o individual'
        ];
        
        html += `<div class="cluster-card cluster-${profile.cluster}">
            <h4>Cluster ${profile.cluster}: "${clusterNames[profile.cluster]}"</h4>
            <p><strong>Tamanho:</strong> ${profile.size} respondentes (${profile.percentage}%)</p>
            <p><strong>Descri√ß√£o:</strong> ${clusterDescriptions[profile.cluster]}</p>
            <div class="cluster-stats">`;
        
        Object.entries(profile.characteristics).forEach(([key, value]) => {
            html += `<div class="cluster-stat">
                <strong>${key}:</strong> ${value}
            </div>`;
        });
        
        html += `</div></div>`;
    });
    
    profilesDiv.innerHTML = html;
}

// Renderizar Profiles Tab
function renderProfilesTab(clusterProfiles, chiSquareResults) {
    // Atualizar percentuais das personas
    if (clusterProfiles.length >= 4) {
        document.getElementById('persona1Pct').textContent = clusterProfiles[0].percentage + '%';
        document.getElementById('persona2Pct').textContent = clusterProfiles[1].percentage + '%';
        document.getElementById('persona3Pct').textContent = clusterProfiles[2].percentage + '%';
        document.getElementById('persona4Pct').textContent = clusterProfiles[3].percentage + '%';
    }
    
    // Cross analysis - exemplo simplificado
    const wcagFreq = analyzer.getFrequencies('7 - Voc√™ utiliza as diretrizes do W3C/WCAG no seu trabalho?');
    const implFreq = analyzer.getFrequencies('11 - Voc√™ ou seu time implementa t√©cnicas de acessibilidade (para pessoas com defici√™ncia) durante a execu√ß√£o do projeto ou depois que o produto/sistema j√° est√° desenvolvido?');
    
    visualizer.createCrossAnalysis('crossAnalysis', {
        labels: ['Nunca', 'Raramente', '√Äs vezes', 'Frequentemente', 'Sempre'],
        datasets: [
            {
                label: 'Conhece WCAG',
                data: wcagFreq.slice(0, 5).map(f => f.count)
            },
            {
                label: 'Implementa',
                data: implFreq.slice(0, 5).map(f => f.count)
            }
        ]
    });
    
    // Chi-Square visualizations
    if (chiSquareResults && chiSquareResults.length > 0) {
        visualizer.createChiSquareResults('chiSquareChart', chiSquareResults);
        visualizer.createCramerVChart('cramerVChart', chiSquareResults);
        
        // Display detailed chi-square table
        const chiSquareDiv = document.getElementById('chiSquareDetails');
        if (chiSquareDiv) {
            let html = '<h4>üìä Testes de Independ√™ncia Chi-Quadrado</h4>';
            html += '<div class="chi-results-grid">';
            
            chiSquareResults.forEach((result, idx) => {
                const sigClass = result.significant ? 'significant' : 'not-significant';
                const sigText = result.significant ? '‚úÖ Significativo' : '‚ùå N√£o Significativo';
                const sigColor = result.significant ? '#10b981' : '#9ca3af';
                
                html += `<div class="chi-result-card ${sigClass}" style="border-left: 4px solid ${sigColor}">
                    <h5>${idx + 1}. ${result.var1} √ó ${result.var2}</h5>
                    <div class="chi-stats">
                        <p><strong>œá¬≤:</strong> ${result.chiSquare.toFixed(2)}</p>
                        <p><strong>df:</strong> ${result.df}</p>
                        <p><strong>p-valor:</strong> ${result.pValue.toFixed(4)}</p>
                        <p><strong>V de Cram√©r:</strong> ${result.cramerV.toFixed(3)}</p>
                        <p style="color: ${sigColor}; font-weight: bold;">${sigText}</p>
                    </div>
                </div>`;
            });
            
            html += '</div>';
            chiSquareDiv.innerHTML = html;
        }
    }
}

// Renderizar Export Tab
function renderExportTab() {
    const summary = document.getElementById('executiveSummary');
    
    const totalResponses = analyzer.rawData.length;
    const clusters = analyzer.clusterResults.k;
    const topCorr = analyzer.getTopCorrelations(5);
    const variance2PC = (analyzer.pcaResults.cumulativeVariance[1] * 100).toFixed(1);
    
    let html = `
        <h4>üìä Resumo Executivo da An√°lise</h4>
        <p><strong>Data da An√°lise:</strong> ${new Date().toLocaleDateString('pt-BR')}</p>
        
        <h4>1. Dados Gerais</h4>
        <ul>
            <li>Total de respondentes: <strong>${totalResponses}</strong></li>
            <li>Total de quest√µes: <strong>${analyzer.columnNames.length}</strong></li>
            <li>Taxa de completude: <strong>100%</strong></li>
        </ul>
        
        <h4>2. Principais Descobertas</h4>
        <ul>
            <li><strong>${clusters} grupos distintos</strong> de respondentes foram identificados atrav√©s de clustering K-Means</li>
            <li>Os primeiros 2 componentes principais explicam <strong>${variance2PC}%</strong> da vari√¢ncia total</li>
            <li>A correla√ß√£o mais forte encontrada foi entre <strong>${topCorr[0].var1}</strong> e <strong>${topCorr[0].var2}</strong> (r=${topCorr[0].correlation.toFixed(3)})</li>
        </ul>
        
        <h4>3. Perfis Identificados</h4>
        <ul>
            <li><strong>Grupo de Baixo Engajamento (‚âà60%):</strong> Profissionais com pouco conhecimento de acessibilidade</li>
            <li><strong>Grupo Engajado (‚âà25%):</strong> Profissionais com alto conhecimento e implementa√ß√£o</li>
            <li><strong>Designers Conscientes (‚âà14%):</strong> Profissionais com conhecimento moderado</li>
            <li><strong>Casos Especiais (‚âà1%):</strong> Outliers que requerem an√°lise individual</li>
        </ul>
        
        <h4>4. Recomenda√ß√µes</h4>
        <ul>
            <li>Focar em <strong>treinamento b√°sico</strong> para o grupo de baixo engajamento (60% dos respondentes)</li>
            <li>Criar <strong>programa de mentoria</strong> envolvendo o grupo engajado como l√≠deres</li>
            <li>Desenvolver <strong>ferramentas pr√°ticas</strong> para auxiliar designers conscientes</li>
            <li>Estabelecer <strong>m√©tricas de acompanhamento</strong> para medir evolu√ß√£o da acessibilidade</li>
        </ul>
    `;
    
    summary.innerHTML = html;
}

// Fun√ß√µes de Exporta√ß√£o

function exportHTML() {
    const htmlContent = `
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Relat√≥rio de An√°lise Multivariada</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }
        h1 { color: #2563eb; }
        h2 { color: #1e293b; margin-top: 30px; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
        th { background-color: #2563eb; color: white; }
        .stat { background: #f8fafc; padding: 15px; margin: 10px 0; border-radius: 8px; }
    </style>
</head>
<body>
    <h1>üìä Relat√≥rio de An√°lise Multivariada - Acessibilidade Web</h1>
    <p><strong>Data:</strong> ${new Date().toLocaleDateString('pt-BR')}</p>
    ${document.getElementById('executiveSummary').innerHTML}
</body>
</html>
    `;
    
    downloadFile('relatorio_analise.html', htmlContent, 'text/html');
}

function exportCorrelation() {
    let csv = 'Vari√°vel 1,Vari√°vel 2,Correla√ß√£o,For√ßa\n';
    const allCorr = analyzer.getTopCorrelations(1000); // Exporta todas as correla√ß√µes
    
    allCorr.forEach(corr => {
        const strength = Math.abs(corr.correlation) > 0.5 ? 'Forte' : 
                        Math.abs(corr.correlation) > 0.3 ? 'Moderada' : 'Fraca';
        csv += `"${corr.var1}","${corr.var2}",${corr.correlation},${strength}\n`;
    });
    
    downloadFile('correlacoes_completas.csv', csv, 'text/csv');
}

function exportClusters() {
    let csv = analyzer.columnNames.join(',') + ',Cluster\n';
    
    analyzer.rawData.forEach((row, idx) => {
        const values = analyzer.columnNames.map(col => `"${row[col]}"`).join(',');
        csv += `${values},${analyzer.clusterResults.clusters[idx]}\n`;
    });
    
    downloadFile('dados_com_clusters.csv', csv, 'text/csv');
}

function exportJSON() {
    const summary = {
        metadata: {
            date: new Date().toISOString(),
            totalResponses: analyzer.rawData.length,
            totalQuestions: analyzer.columnNames.length
        },
        correlations: analyzer.getTopCorrelations(1000), // Todas as correla√ß√µes
        pca: {
            explainedVariance: analyzer.pcaResults.explainedVariance,
            cumulativeVariance: analyzer.pcaResults.cumulativeVariance,
            loadings: analyzer.pcaResults.loadings
        },
        clustering: {
            k: analyzer.clusterResults.k,
            clusterDistribution: analyzer.characterizeClusters(),
            clusters: analyzer.clusterResults.clusters
        }
    };
    
    downloadFile('analise_completa.json', JSON.stringify(summary, null, 2), 'application/json');
}

function downloadFile(filename, content, type) {
    const blob = new Blob([content], { type });
    const url = window.URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    window.URL.revokeObjectURL(url);
}

// Modal de Informa√ß√µes
function showInfo(section) {
    const modal = document.getElementById('infoModal');
    const modalTitle = document.getElementById('modalTitle');
    const modalBody = document.getElementById('modalBody');
    
    const infoContent = {
        descriptive: {
            title: 'üìä An√°lise Descritiva',
            content: `
                <h3>O que √©?</h3>
                <p>A an√°lise descritiva fornece um resumo das caracter√≠sticas principais dos dados atrav√©s de estat√≠sticas e visualiza√ß√µes. 
                Ela permite entender a distribui√ß√£o, frequ√™ncia e padr√µes b√°sicos das vari√°veis analisadas.</p>
                
                <h3>Quando usar?</h3>
                <ul>
                    <li>Para explorar e compreender a estrutura dos dados</li>
                    <li>Identificar padr√µes e tend√™ncias gerais</li>
                    <li>Detectar outliers e valores at√≠picos</li>
                    <li>Como primeira etapa antes de an√°lises mais complexas</li>
                </ul>
                
                <h3>Como interpretar?</h3>
                <p>Os gr√°ficos de barras mostram a <strong>frequ√™ncia</strong> de cada categoria. Categorias mais altas indicam maior 
                representatividade na amostra. Gr√°ficos de pizza mostram a <strong>propor√ß√£o</strong> relativa entre categorias.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncia Principal:</strong><br>
                    HAIR, J. F. et al. <em>Multivariate Data Analysis</em>. 8. ed. Boston: Cengage Learning, 2018. Cap√≠tulo 2: 
                    "Examining Your Data" - Fundamentos de an√°lise explorat√≥ria de dados.
                </div>
            `
        },
        correlation: {
            title: 'üîó An√°lise de Correla√ß√£o (Spearman)',
            content: `
                <h3>O que √©?</h3>
                <p>A <strong>Correla√ß√£o de Spearman</strong> mede a for√ßa e dire√ß√£o da rela√ß√£o monot√¥nica entre duas vari√°veis. 
                Valores variam de -1 (correla√ß√£o negativa perfeita) a +1 (correla√ß√£o positiva perfeita).</p>
                
                <h3>Interpreta√ß√£o dos valores:</h3>
                <ul>
                    <li><strong>|r| > 0.7:</strong> Correla√ß√£o muito forte</li>
                    <li><strong>0.5 < |r| ‚â§ 0.7:</strong> Correla√ß√£o forte</li>
                    <li><strong>0.3 < |r| ‚â§ 0.5:</strong> Correla√ß√£o moderada</li>
                    <li><strong>|r| ‚â§ 0.3:</strong> Correla√ß√£o fraca</li>
                </ul>
                
                <h3>Por que Spearman?</h3>
                <p>Diferente da correla√ß√£o de Pearson, Spearman √© <strong>n√£o-param√©trica</strong> e baseada em ranks, 
                sendo mais apropriada para dados ordinais (como escalas Likert) e dados com distribui√ß√£o n√£o-normal.</p>
                
                <h3>Aplica√ß√£o neste estudo:</h3>
                <p>Identifica quais pr√°ticas de acessibilidade est√£o relacionadas entre si. Por exemplo, se h√° correla√ß√£o 
                forte entre "uso de WCAG" e "implementa√ß√£o de t√©cnicas".</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    SPEARMAN, C. (1904). "The proof and measurement of association between two things". 
                    <em>American Journal of Psychology</em>, 15(1), 72-101. [Artigo original]<br><br>
                    COHEN, J. (1988). <em>Statistical Power Analysis for the Behavioral Sciences</em>. 2nd ed. 
                    Hillsdale: Lawrence Erlbaum. [Interpreta√ß√£o de tamanhos de efeito]
                </div>
            `
        },
        pca: {
            title: 'üéØ PCA - An√°lise de Componentes Principais',
            content: `
                <h3>O que √©?</h3>
                <p>PCA (Principal Component Analysis) √© uma t√©cnica de <strong>redu√ß√£o de dimensionalidade</strong> que transforma 
                vari√°veis correlacionadas em um conjunto menor de vari√°veis n√£o-correlacionadas chamadas componentes principais.</p>
                
                <h3>Como funciona?</h3>
                <ol>
                    <li>Identifica as dire√ß√µes de maior vari√¢ncia nos dados</li>
                    <li>Projeta os dados nessas dire√ß√µes (componentes principais)</li>
                    <li>Os primeiros componentes capturam a maior parte da varia√ß√£o</li>
                </ol>
                
                <h3>Gr√°ficos apresentados:</h3>
                <ul>
                    <li><strong>Scree Plot:</strong> Mostra a vari√¢ncia explicada por cada componente</li>
                    <li><strong>Vari√¢ncia Acumulada:</strong> Quanto dos dados √© explicado pelos primeiros N componentes</li>
                    <li><strong>Biplot:</strong> Visualiza observa√ß√µes e vari√°veis nos 2 primeiros componentes</li>
                </ul>
                
                <h3>Como interpretar?</h3>
                <p>Componentes com alta vari√¢ncia explicada (>10%) s√£o importantes. Geralmente, busca-se explicar 
                70-90% da vari√¢ncia total com os primeiros componentes. As setas no Biplot mostram a contribui√ß√£o 
                de cada vari√°vel original.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    JOLLIFFE, I. T.; CADIMA, J. (2016). "Principal component analysis: a review and recent developments". 
                    <em>Philosophical Transactions of the Royal Society A</em>, 374(2065). [Revis√£o moderna]<br><br>
                    ABDI, H.; WILLIAMS, L. J. (2010). "Principal component analysis". 
                    <em>Wiley Interdisciplinary Reviews: Computational Statistics</em>, 2(4), 433-459. [Guia pr√°tico]
                </div>
            `
        },
        clustering: {
            title: 'üîµ An√°lise de Clusters',
            content: `
                <h3>O que √©?</h3>
                <p>Clustering √© uma t√©cnica de <strong>aprendizado n√£o-supervisionado</strong> que agrupa observa√ß√µes 
                similares. Este projeto implementa tr√™s m√©todos complementares:</p>
                
                <h3>1. K-Means Clustering</h3>
                <p>Particiona dados em K clusters, minimizando a vari√¢ncia intra-cluster. O <strong>M√©todo do Cotovelo</strong> 
                ajuda a determinar o n√∫mero ideal de clusters (onde a curva "dobra").</p>
                <ul>
                    <li><strong>Vantagem:</strong> R√°pido e eficiente</li>
                    <li><strong>Limita√ß√£o:</strong> Requer especificar K previamente</li>
                </ul>
                
                <h3>2. t-SNE (t-Distributed Stochastic Neighbor Embedding)</h3>
                <p>T√©cnica de <strong>redu√ß√£o dimensional n√£o-linear</strong> que preserva rela√ß√µes de proximidade local. 
                Ideal para visualiza√ß√£o de estruturas complexas em 2D.</p>
                <ul>
                    <li><strong>Vantagem:</strong> Revela estruturas n√£o-lineares</li>
                    <li><strong>Limita√ß√£o:</strong> Computacionalmente intensivo</li>
                </ul>
                
                <h3>3. Clustering Hier√°rquico (Ward)</h3>
                <p>Cria uma <strong>hierarquia de clusters</strong> atrav√©s de merges sucessivos. O dendrograma mostra 
                a estrutura hier√°rquica completa.</p>
                <ul>
                    <li><strong>Vantagem:</strong> N√£o precisa definir K previamente</li>
                    <li><strong>M√©todo Ward:</strong> Minimiza a vari√¢ncia dentro dos clusters</li>
                </ul>
                
                <h3>Interpreta√ß√£o dos Clusters:</h3>
                <p>Cada cluster representa um <strong>perfil distinto</strong> de respondentes. Analise as caracter√≠sticas 
                predominantes de cada grupo para criar personas e entender padr√µes de comportamento.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    JAIN, A. K. (2010). "Data Clustering: 50 Years Beyond K-means". 
                    <em>Pattern Recognition Letters</em>, 31(8), 651-666. [Revis√£o hist√≥rica]<br><br>
                    VAN DER MAATEN, L.; HINTON, G. (2008). "Visualizing Data using t-SNE". 
                    <em>Journal of Machine Learning Research</em>, 9, 2579-2605. [t-SNE original]<br><br>
                    KAUFMAN, L.; ROUSSEEUW, P. J. (1990). <em>Finding Groups in Data: An Introduction to Cluster Analysis</em>. 
                    Wiley. [Clustering hier√°rquico]
                </div>
            `
        },
        profiles: {
            title: 'üë• An√°lise de Perfis e Chi-Quadrado',
            content: `
                <h3>Perfis dos Respondentes (Personas)</h3>
                <p>Com base nos clusters identificados, foram criadas <strong>personas</strong> que representam perfis 
                t√≠picos de profissionais em rela√ß√£o √†s pr√°ticas de acessibilidade web.</p>
                
                <h3>Como as personas foram criadas?</h3>
                <ol>
                    <li>Clustering agrupa respondentes com caracter√≠sticas similares</li>
                    <li>An√°lise das caracter√≠sticas predominantes de cada cluster</li>
                    <li>Cria√ß√£o de perfis arquet√≠picos (personas) representativos</li>
                    <li>Defini√ß√£o de estrat√©gias espec√≠ficas para cada perfil</li>
                </ol>
                
                <h3>Teste Chi-Quadrado (œá¬≤)</h3>
                <p>O <strong>teste chi-quadrado de Pearson</strong> avalia se existe <strong>associa√ß√£o estat√≠stica</strong> 
                entre duas vari√°veis categ√≥ricas. Testa a hip√≥tese de independ√™ncia entre as vari√°veis.</p>
                
                <h3>Interpreta√ß√£o:</h3>
                <ul>
                    <li><strong>p-value < 0.05:</strong> Vari√°veis s√£o dependentes (associadas)</li>
                    <li><strong>p-value ‚â• 0.05:</strong> N√£o h√° evid√™ncia de associa√ß√£o</li>
                    <li><strong>V de Cram√©r:</strong> Mede a for√ßa da associa√ß√£o (0 a 1)
                        <ul>
                            <li>V > 0.3: Associa√ß√£o forte</li>
                            <li>0.1 < V ‚â§ 0.3: Associa√ß√£o moderada</li>
                            <li>V ‚â§ 0.1: Associa√ß√£o fraca</li>
                        </ul>
                    </li>
                </ul>
                
                <h3>An√°lises Cruzadas</h3>
                <p>As an√°lises cruzadas mostram como diferentes vari√°veis se relacionam, revelando padr√µes como:</p>
                <ul>
                    <li>Rela√ß√£o entre escolaridade e conhecimento de WCAG</li>
                    <li>Conex√£o entre uso de ferramentas e implementa√ß√£o pr√°tica</li>
                    <li>Impacto da √°rea de atua√ß√£o nas pr√°ticas de acessibilidade</li>
                </ul>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    PEARSON, K. (1900). "On the criterion that a given system of deviations from the probable in the case 
                    of a correlated system of variables is such that it can be reasonably supposed to have arisen from 
                    random sampling". <em>Philosophical Magazine</em>, Series 5, 50(302), 157-175. [Chi-quadrado original]<br><br>
                    AGRESTI, A. (2012). <em>Categorical Data Analysis</em>. 3rd ed. Wiley. [Refer√™ncia moderna completa]<br><br>
                    CRAM√âR, H. (1946). <em>Mathematical Methods of Statistics</em>. Princeton University Press. 
                                        [V de Cram√©r - medida de associa√ß√£o]
                </div>
            `
        },
        clusterDist: {
            title: 'üìä Distribui√ß√£o dos Clusters',
            content: `
                <h3>O que mostra?</h3>
                <p>Este gr√°fico de barras mostra a <strong>quantidade de observa√ß√µes</strong> (respondentes) atribu√≠das 
                a cada cluster identificado pelo algoritmo K-Means.</p>
                
                <h3>Como interpretar?</h3>
                <ul>
                    <li><strong>Altura das barras:</strong> N√∫mero de respondentes em cada cluster</li>
                    <li><strong>Distribui√ß√£o equilibrada:</strong> Clusters de tamanhos similares indicam grupos bem definidos</li>
                    <li><strong>Clusters muito pequenos:</strong> Podem indicar outliers ou grupos especiais</li>
                    <li><strong>Clusters muito grandes:</strong> Podem indicar que o grupo precisa ser subdividido</li>
                </ul>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// Ap√≥s executar K-Means, conta-se quantos pontos<br>
// foram atribu√≠dos a cada cluster<br>
<br>
const clusterCounts = [];<br>
for (let i = 0; i < k; i++) {<br>
&nbsp;&nbsp;const count = clusters.filter(c => c === i).length;<br>
&nbsp;&nbsp;clusterCounts.push(count);<br>
}<br>
<br>
// Cria gr√°fico de barras com as contagens
                </div>
                
                <h3>Import√¢ncia</h3>
                <p>A distribui√ß√£o dos clusters ajuda a avaliar se o valor de k escolhido √© adequado. 
                Clusters muito desiguais podem indicar necessidade de ajuste no n√∫mero de clusters.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncia:</strong><br>
                    ROUSSEEUW, P. J. (1987). "Silhouettes: A graphical aid to the interpretation and validation 
                    of cluster analysis". <em>Journal of Computational and Applied Mathematics</em>, 20, 53-65.
                </div>
            `
        },
        clusterPCA: {
            title: 'üéØ Visualiza√ß√£o dos Clusters (Proje√ß√£o PCA)',
            content: `
                <h3>O que mostra?</h3>
                <p>Este gr√°fico de dispers√£o mostra os <strong>clusters identificados</strong> projetados nas 
                <strong>duas primeiras componentes principais (PC1 e PC2)</strong> do PCA. Cada cor representa um cluster diferente.</p>
                
                <h3>Por que usar PCA para visualiza√ß√£o?</h3>
                <p>Os dados originais t√™m <strong>19 dimens√µes</strong> (vari√°veis). √â imposs√≠vel visualizar 19 dimens√µes diretamente. 
                PCA reduz para 2D preservando a maior vari√¢ncia poss√≠vel, permitindo visualizar a separa√ß√£o dos clusters.</p>
                
                <h3>Como interpretar?</h3>
                <ul>
                    <li><strong>Pontos pr√≥ximos:</strong> Respondentes com caracter√≠sticas similares</li>
                    <li><strong>Clusters separados:</strong> Indica boa separa√ß√£o - grupos distintos</li>
                    <li><strong>Clusters sobrepostos:</strong> Grupos com caracter√≠sticas similares, pode indicar necessidade de reduzir k</li>
                    <li><strong>Outliers:</strong> Pontos isolados representam casos at√≠picos</li>
                </ul>
                
                <h3>Cores dos clusters:</h3>
                <ul>
                    <li>üî¥ <strong>Cluster 0 (Vermelho):</strong> Baixo engajamento</li>
                    <li>üîµ <strong>Cluster 1 (Azul):</strong> Engajados</li>
                    <li>üü¢ <strong>Cluster 2 (Verde):</strong> Designers conscientes</li>
                    <li>üü° <strong>Cluster 3 (Amarelo):</strong> Casos especiais</li>
                </ul>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// 1. Executa PCA nos dados normalizados<br>
const pcaResults = performPCA();<br>
<br>
// 2. Executa K-Means nos dados normalizados<br>
const clusters = performKMeans(k=4);<br>
<br>
// 3. Plota pontos usando PC1 e PC2 como coordenadas<br>
// e cor baseada no cluster atribu√≠do<br>
for (let i = 0; i < data.length; i++) {<br>
&nbsp;&nbsp;const x = pcaResults.projectedData[i][0]; // PC1<br>
&nbsp;&nbsp;const y = pcaResults.projectedData[i][1]; // PC2<br>
&nbsp;&nbsp;const color = clusterColors[clusters[i]];<br>
&nbsp;&nbsp;plot(x, y, color);<br>
}
                </div>
                
                <h3>Limita√ß√µes</h3>
                <p>A visualiza√ß√£o mostra apenas os dois primeiros componentes principais, que podem n√£o capturar 
                toda a vari√¢ncia dos dados. Clusters que se sobrep√µem em 2D podem estar bem separados em dimens√µes superiores.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    JOLLIFFE, I. T. (2002). <em>Principal Component Analysis</em>. 2nd ed. Springer.<br><br>
                    HARTIGAN, J. A.; WONG, M. A. (1979). "Algorithm AS 136: A K-Means Clustering Algorithm". 
                    <em>Journal of the Royal Statistical Society. Series C</em>, 28(1), 100-108.
                </div>
            `
        },
        tsneViz: {
            title: 'üîÆ t-SNE Visualization',
            content: `
                <h3>O que √© t-SNE?</h3>
                <p><strong>t-SNE</strong> (t-Distributed Stochastic Neighbor Embedding) √© uma t√©cnica de 
                <strong>redu√ß√£o dimensional n√£o-linear</strong> especialmente eficaz para visualiza√ß√£o de dados de alta dimensionalidade.</p>
                
                <h3>Diferen√ßa entre t-SNE e PCA:</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">PCA</th>
                        <th style="padding: 10px; text-align: left;">t-SNE</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Linear</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">N√£o-linear</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Preserva vari√¢ncia global</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Preserva estruturas locais</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">R√°pido</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Computacionalmente intensivo</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Dist√¢ncias globais confi√°veis</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Dist√¢ncias locais confi√°veis</td>
                    </tr>
                </table>
                
                <h3>Como funciona?</h3>
                <ol>
                    <li><strong>Espa√ßo de alta dimens√£o:</strong> Calcula probabilidades de similaridade entre pontos usando distribui√ß√£o Gaussiana</li>
                    <li><strong>Espa√ßo 2D:</strong> Inicializa pontos aleatoriamente</li>
                    <li><strong>Otimiza√ß√£o:</strong> Ajusta posi√ß√µes para que as probabilidades de similaridade em 2D correspondam √†s do espa√ßo original</li>
                    <li><strong>Diverg√™ncia KL:</strong> Minimiza a diverg√™ncia de Kullback-Leibler entre as duas distribui√ß√µes</li>
                </ol>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// Implementa√ß√£o completa em analyzer.js<br>
performTSNE(perplexity = 30, iterations = 1000, learningRate = 200) {<br>
&nbsp;&nbsp;// 1. Normaliza dados<br>
&nbsp;&nbsp;const normalized = this.normalizeData(this.numericData);<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;// 2. Calcula matriz P (probabilidades no espa√ßo original)<br>
&nbsp;&nbsp;const P = this.computeP(normalized, perplexity);<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;// 3. Inicializa Y aleatoriamente (posi√ß√µes 2D)<br>
&nbsp;&nbsp;let Y = Array(n).fill().map(() => [random(), random()]);<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;// 4. Otimiza√ß√£o por gradiente descendente<br>
&nbsp;&nbsp;for (let iter = 0; iter < 1000; iter++) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;const Q = this.computeQ(Y); // Probabilidades 2D<br>
&nbsp;&nbsp;&nbsp;&nbsp;const gradient = this.computeTSNEGradient(P, Q, Y);<br>
&nbsp;&nbsp;&nbsp;&nbsp;Y = updatePositions(Y, gradient, learningRate);<br>
&nbsp;&nbsp;}<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;return { Y: Y }; // Coordenadas 2D finais<br>
}
                </div>
                
                <h3>Par√¢metros usados:</h3>
                <ul>
                    <li><strong>Perplexity = 30:</strong> Balan√ßo entre estruturas locais/globais (t√≠pico: 5-50)</li>
                    <li><strong>Iterations = 1000:</strong> N√∫mero de itera√ß√µes de otimiza√ß√£o</li>
                    <li><strong>Learning Rate = 200:</strong> Taxa de aprendizado do gradiente descendente</li>
                </ul>
                
                <h3>Como interpretar?</h3>
                <ul>
                    <li><strong>Grupos compactos:</strong> Pontos similares formam aglomerados</li>
                    <li><strong>Dist√¢ncias locais:</strong> Pontos pr√≥ximos s√£o realmente similares</li>
                    <li><strong>‚ö†Ô∏è Dist√¢ncias globais:</strong> Dist√¢ncia entre grupos n√£o √© confi√°vel</li>
                    <li><strong>‚ö†Ô∏è Tamanho dos clusters:</strong> N√£o indica necessariamente o tamanho real</li>
                </ul>
                
                <h3>Cuidados na interpreta√ß√£o:</h3>
                <p>‚ö†Ô∏è <strong>t-SNE n√£o preserva dist√¢ncias globais!</strong> Dois clusters distantes no gr√°fico 
                n√£o necessariamente s√£o muito diferentes. Use apenas para entender estruturas locais.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    <br>
                    <strong>Artigo Original:</strong><br>
                    VAN DER MAATEN, L.; HINTON, G. (2008). "Visualizing Data using t-SNE". 
                    <em>Journal of Machine Learning Research</em>, 9, 2579-2605.<br><br>
                    
                    <strong>Guia de Interpreta√ß√£o:</strong><br>
                    WATTENBERG, M.; VI√âGAS, F.; JOHNSON, I. (2016). "How to Use t-SNE Effectively". 
                    <em>Distill</em>. doi:10.23915/distill.00002
                </div>
            `
        },
        tsneClusters: {
            title: 'üé® t-SNE com Clusters Coloridos',
            content: `
                <h3>O que mostra?</h3>
                <p>Esta visualiza√ß√£o combina <strong>t-SNE</strong> (para proje√ß√£o 2D n√£o-linear) com as 
                <strong>atribui√ß√µes de clusters do K-Means</strong>. Cada ponto √© colorido de acordo com seu cluster.</p>
                
                <h3>Por que combinar t-SNE + K-Means?</h3>
                <ul>
                    <li><strong>K-Means:</strong> Agrupa dados no espa√ßo original de 19 dimens√µes</li>
                    <li><strong>t-SNE:</strong> Cria visualiza√ß√£o 2D preservando estruturas locais</li>
                    <li><strong>Combina√ß√£o:</strong> Permite ver se os clusters identificados pelo K-Means 
                    formam grupos visualmente separados</li>
                </ul>
                
                <h3>O que esperar?</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Observa√ß√£o</th>
                        <th style="padding: 10px; text-align: left;">Interpreta√ß√£o</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>‚úÖ Clusters bem separados</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Excelente! K-Means identificou grupos distintos</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>‚ö†Ô∏è Clusters parcialmente sobrepostos</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Normal. Alguns grupos t√™m caracter√≠sticas similares</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>‚ùå Cores completamente misturadas</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">K-Means pode n√£o ser adequado, ou k incorreto</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>üîç Cluster isolado pequeno</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Outliers ou grupo especial de interesse</td>
                    </tr>
                </table>
                
                <h3>Como √© criado?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// 1. Executa t-SNE (reduz para 2D)<br>
const tsneResults = analyzer.performTSNE(30, 1000, 200);<br>
const Y = tsneResults.Y; // Coordenadas 2D<br>
<br>
// 2. Usa clusters j√° calculados pelo K-Means<br>
const clusters = analyzer.clusterResults.clusters;<br>
<br>
// 3. Plota cada ponto com cor do seu cluster<br>
const colors = ['red', 'blue', 'green', 'yellow'];<br>
for (let i = 0; i < Y.length; i++) {<br>
&nbsp;&nbsp;const x = Y[i][0];<br>
&nbsp;&nbsp;const y = Y[i][1];<br>
&nbsp;&nbsp;const color = colors[clusters[i]];<br>
&nbsp;&nbsp;plot(x, y, color);<br>
}
                </div>
                
                <h3>Diferen√ßa para "Visualiza√ß√£o dos Clusters (PCA)"</h3>
                <ul>
                    <li><strong>PCA:</strong> Proje√ß√£o linear, preserva vari√¢ncia global, dist√¢ncias confi√°veis</li>
                    <li><strong>t-SNE:</strong> Proje√ß√£o n√£o-linear, preserva estruturas locais, melhor separa√ß√£o visual</li>
                    <li><strong>Uso:</strong> Compare ambos! Se clusters se separam em ambos, √© forte evid√™ncia de grupos distintos</li>
                </ul>
                
                <h3>Valida√ß√£o dos clusters:</h3>
                <p>Se os clusters aparecem bem separados tanto na proje√ß√£o PCA quanto no t-SNE, isso √© uma 
                <strong>forte evid√™ncia</strong> de que o K-Means identificou grupos realmente distintos nos dados originais.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    VAN DER MAATEN, L.; HINTON, G. (2008). "Visualizing Data using t-SNE". 
                    <em>Journal of Machine Learning Research</em>, 9, 2579-2605.<br><br>
                    
                    KOBAK, D.; BERENS, P. (2019). "The art of using t-SNE for single-cell transcriptomics". 
                    <em>Nature Communications</em>, 10(1), 5416. [Melhores pr√°ticas de uso]
                </div>
            `
        },
        dendrogram: {
            title: 'üå≥ Dendrograma - Clustering Hier√°rquico',
            content: `
                <h3>O que √© um Dendrograma?</h3>
                <p>Um dendrograma √© uma visualiza√ß√£o em forma de <strong>√°rvore</strong> que mostra como os dados 
                foram agrupados hierarquicamente. A altura das conex√µes indica a <strong>dist√¢ncia (dissimilaridade)</strong> 
                entre os clusters sendo unidos.</p>
                
                <h3>Como √© constru√≠do?</h3>
                <ol>
                    <li><strong>In√≠cio:</strong> Cada observa√ß√£o √© um cluster individual (73 clusters)</li>
                    <li><strong>Merges sucessivos:</strong> Os dois clusters mais pr√≥ximos s√£o unidos</li>
                    <li><strong>Repeti√ß√£o:</strong> Processo continua at√© restar apenas 1 cluster</li>
                    <li><strong>Resultado:</strong> Hierarquia completa de fus√µes</li>
                </ol>
                
                <h3>M√©todo de Linkage: Ward</h3>
                <p>Este projeto usa o <strong>m√©todo de Ward</strong>, que minimiza a vari√¢ncia dentro dos clusters. 
                A dist√¢ncia de fus√£o √© calculada como:</p>
                
                <div style="background: #f0f4ff; padding: 15px; border-radius: 8px; margin: 15px 0;">
                    <code style="font-size: 1.1em;">
                        d<sub>Ward</sub>(C‚ÇÅ, C‚ÇÇ) = ‚àö[(2¬∑n‚ÇÅ¬∑n‚ÇÇ)/(n‚ÇÅ+n‚ÇÇ)] ¬∑ ||Œº‚ÇÅ - Œº‚ÇÇ||
                    </code>
                    <p style="margin-top: 10px; font-size: 0.9em;">
                        Onde:<br>
                        ‚Ä¢ n‚ÇÅ, n‚ÇÇ = tamanhos dos clusters<br>
                        ‚Ä¢ Œº‚ÇÅ, Œº‚ÇÇ = centroides dos clusters<br>
                        ‚Ä¢ ||¬∑|| = dist√¢ncia Euclidiana
                    </p>
                </div>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
performHierarchicalClustering() {<br>
&nbsp;&nbsp;// 1. Inicializa: cada ponto √© um cluster<br>
&nbsp;&nbsp;const clusters = data.map((point, i) => ({<br>
&nbsp;&nbsp;&nbsp;&nbsp;id: i,<br>
&nbsp;&nbsp;&nbsp;&nbsp;points: [i],<br>
&nbsp;&nbsp;&nbsp;&nbsp;centroid: point,<br>
&nbsp;&nbsp;&nbsp;&nbsp;height: 0<br>
&nbsp;&nbsp;}));<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;const merges = [];<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;// 2. Loop at√© sobrar 1 cluster<br>
&nbsp;&nbsp;while (clusters.length > 1) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;// Encontra par mais pr√≥ximo (Ward)<br>
&nbsp;&nbsp;&nbsp;&nbsp;const [i, j, dist] = findClosestPair(clusters);<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;// Une os clusters<br>
&nbsp;&nbsp;&nbsp;&nbsp;const newCluster = mergeClusters(clusters[i], clusters[j]);<br>
&nbsp;&nbsp;&nbsp;&nbsp;merges.push({ cluster1: i, cluster2: j, distance: dist });<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;// Remove antigos, adiciona novo<br>
&nbsp;&nbsp;&nbsp;&nbsp;clusters.splice(i, 1); clusters.splice(j, 1);<br>
&nbsp;&nbsp;&nbsp;&nbsp;clusters.push(newCluster);<br>
&nbsp;&nbsp;}<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;return { merges, rootCluster: clusters[0] };<br>
}
                </div>
                
                <h3>Como interpretar o gr√°fico?</h3>
                <ul>
                    <li><strong>Eixo X:</strong> Sequ√™ncia de merges (√∫ltimos 15 mostrados)</li>
                    <li><strong>Eixo Y:</strong> Dist√¢ncia de linkage (Ward)</li>
                    <li><strong>Tend√™ncia crescente:</strong> Normal - fus√µes finais s√£o mais distantes</li>
                    <li><strong>Saltos grandes:</strong> Indicam boa separa√ß√£o entre clusters</li>
                </ul>
                
                <h3>Como determinar o n√∫mero de clusters?</h3>
                <p>Procure por <strong>grandes saltos verticais</strong> na dist√¢ncia. O n√∫mero de clusters ideal 
                √© geralmente encontrado antes de um grande salto. Por exemplo:</p>
                <ul>
                    <li>Se h√° grande salto ao passar de 4 para 3 clusters ‚Üí k=4 √© bom</li>
                    <li>Saltos pequenos e consistentes ‚Üí sem estrutura clara</li>
                </ul>
                
                <h3>Vantagens vs. K-Means:</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Hier√°rquico</th>
                        <th style="padding: 10px; text-align: left;">K-Means</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">N√£o precisa definir k previamente</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Precisa especificar k</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Mostra hierarquia completa</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Apenas parti√ß√£o final</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Lento (O(n¬≥))</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">R√°pido (O(n¬∑k¬∑i))</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Determin√≠stico</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Aleat√≥rio</td>
                    </tr>
                </table>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    <br>
                    <strong>M√©todo de Ward:</strong><br>
                    WARD, J. H. (1963). "Hierarchical Grouping to Optimize an Objective Function". 
                    <em>Journal of the American Statistical Association</em>, 58(301), 236-244.<br><br>
                    
                    <strong>Clustering Hier√°rquico:</strong><br>
                    KAUFMAN, L.; ROUSSEEUW, P. J. (1990). <em>Finding Groups in Data: An Introduction to Cluster Analysis</em>. 
                    Wiley. Cap√≠tulo 5.<br><br>
                    
                    <strong>Compara√ß√£o de M√©todos:</strong><br>
                    MURTAGH, F.; CONTRERAS, P. (2012). "Algorithms for hierarchical clustering: an overview". 
                    <em>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</em>, 2(1), 86-97.
                </div>
            `
        },
        hierarchy: {
            title: 'üìä Estrutura Hier√°rquica',
            content: `
                <h3>O que mostra?</h3>
                <p>Este gr√°fico de barras mostra o <strong>n√∫mero de clusters restantes</strong> ap√≥s cada merge 
                no processo de clustering hier√°rquico. Complementa o dendrograma com uma vis√£o quantitativa.</p>
                
                <h3>Como interpretar?</h3>
                <ul>
                    <li><strong>Eixo X:</strong> N√∫mero do merge (√∫ltimas 20 fus√µes)</li>
                    <li><strong>Eixo Y:</strong> Quantidade de clusters ainda existentes</li>
                    <li><strong>Tend√™ncia:</strong> Decrescente (come√ßa com muitos, termina com 1)</li>
                    <li><strong>Cores:</strong>
                        <ul>
                            <li>üî¥ Vermelho: Acima do corte (mais clusters)</li>
                            <li>üîµ Azul: Abaixo do corte (menos clusters)</li>
                        </ul>
                    </li>
                </ul>
                
                <h3>Corte em k=4</h3>
                <p>O gr√°fico mostra um <strong>corte horizontal em k=4</strong>, indicando a parti√ß√£o em 4 clusters 
                escolhida para este projeto. Barras vermelhas representam estados com mais de 4 clusters, 
                barras azuis representam 4 ou menos clusters.</p>
                
                <h3>Como √© calculado?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// Ap√≥s clustering hier√°rquico completo<br>
const merges = hierarchicalResults.merges;<br>
const n = merges.length; // N√∫mero total de merges<br>
<br>
// Para cada merge, calcula clusters restantes<br>
const levels = merges.map((merge, idx) => ({<br>
&nbsp;&nbsp;mergeNumber: idx + 1,<br>
&nbsp;&nbsp;distance: merge.distance,<br>
&nbsp;&nbsp;clustersRemaining: n - idx  // Come√ßa com n, termina com 1<br>
}));<br>
<br>
// Determina altura de corte para k=4<br>
const sortedDist = merges.map(m => m.distance).sort((a,b) => b-a);<br>
const cutHeight = sortedDist[k - 2]; // k=4 ‚Üí index 2<br>
<br>
// Colore barras: vermelhas se acima do corte, azuis se abaixo
                </div>
                
                <h3>Decis√£o do n√∫mero de clusters</h3>
                <p>Este gr√°fico ajuda a visualizar <strong>em que ponto</strong> da hierarquia estamos cortando 
                para obter k clusters. Um bom corte deve:</p>
                <ul>
                    <li>Estar numa regi√£o com saltos grandes de dist√¢ncia (ver dendrograma)</li>
                    <li>Resultar em clusters de tamanhos razo√°veis</li>
                    <li>Fazer sentido interpretativo para o problema</li>
                </ul>
                
                <h3>Exemplo de interpreta√ß√£o:</h3>
                <p>Se o gr√°fico mostra que nas √∫ltimas 20 fus√µes passamos de 20 clusters para 1, e escolhemos 
                cortar em k=4, estamos pegando um estado intermedi√°rio da hierarquia onde ainda h√° boa separa√ß√£o 
                entre os grupos.</p>
                
                <h3>Rela√ß√£o com o Dendrograma:</h3>
                <ul>
                    <li><strong>Dendrograma:</strong> Mostra COMO os clusters foram unidos (qual com qual, a que dist√¢ncia)</li>
                    <li><strong>Estrutura Hier√°rquica:</strong> Mostra QUANTOS clusters existem a cada passo</li>
                    <li><strong>Juntos:</strong> Oferecem vis√£o completa do processo hier√°rquico</li>
                </ul>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    EVERITT, B. S. et al. (2011). <em>Cluster Analysis</em>. 5th ed. Wiley. Cap√≠tulo 4: 
                    "Hierarchical Clustering".<br><br>
                    
                    HASTIE, T.; TIBSHIRANI, R.; FRIEDMAN, J. (2009). <em>The Elements of Statistical Learning</em>. 
                    2nd ed. Springer. Se√ß√£o 14.3: "Hierarchical Clustering".
                </div>
            `
        },
        clusterProfile: {
            title: 'üìä Perfil dos Clusters',
            content: `
                <h3>O que mostra?</h3>
                <p>Esta se√ß√£o apresenta a <strong>caracteriza√ß√£o detalhada</strong> de cada cluster identificado, 
                descrevendo as caracter√≠sticas predominantes dos respondentes em cada grupo.</p>
                
                <h3>Como s√£o criados os perfis?</h3>
                <ol>
                    <li><strong>Filtragem:</strong> Separa os respondentes por cluster</li>
                    <li><strong>An√°lise de frequ√™ncia:</strong> Para cada vari√°vel importante, identifica o valor mais comum (moda)</li>
                    <li><strong>Interpreta√ß√£o:</strong> Traduz padr√µes estat√≠sticos em perfis descritivos</li>
                    <li><strong>Nomea√ß√£o:</strong> Cria labels intuitivos baseados nas caracter√≠sticas</li>
                </ol>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
characterizeClusters() {<br>
&nbsp;&nbsp;const profiles = [];<br>
&nbsp;&nbsp;const k = clusterResults.k; // N√∫mero de clusters<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;for (let i = 0; i < k; i++) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;// 1. Filtra dados do cluster i<br>
&nbsp;&nbsp;&nbsp;&nbsp;const clusterData = rawData.filter((_, idx) => <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;clusterResults.clusters[idx] === i<br>
&nbsp;&nbsp;&nbsp;&nbsp;);<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;// 2. Calcula estat√≠sticas<br>
&nbsp;&nbsp;&nbsp;&nbsp;const size = clusterData.length;<br>
&nbsp;&nbsp;&nbsp;&nbsp;const percentage = (size / rawData.length * 100).toFixed(1);<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;// 3. Encontra valores mais comuns (moda)<br>
&nbsp;&nbsp;&nbsp;&nbsp;const profile = { cluster: i, size, percentage, characteristics: {} };<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;// Vari√°veis principais analisadas:<br>
&nbsp;&nbsp;&nbsp;&nbsp;// - usa_wcag (conhecimento WCAG)<br>
&nbsp;&nbsp;&nbsp;&nbsp;// - apps_acessiveis (aplica√ß√µes acess√≠veis)<br>
&nbsp;&nbsp;&nbsp;&nbsp;// - preocupa_acessibilidade (n√≠vel de preocupa√ß√£o)<br>
&nbsp;&nbsp;&nbsp;&nbsp;// - implementa_tecnicas (implementa√ß√£o pr√°tica)<br>
&nbsp;&nbsp;&nbsp;&nbsp;// - area_atuacao (√°rea profissional)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;mainCols.forEach(col => {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;const values = clusterData.map(row => row[col]);<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;const mode = findMode(values); // Valor mais frequente<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;profile.characteristics[col] = mode;<br>
&nbsp;&nbsp;&nbsp;&nbsp;});<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;profiles.push(profile);<br>
&nbsp;&nbsp;}<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;return profiles;<br>
}
                </div>
                
                <h3>Informa√ß√µes apresentadas:</h3>
                <ul>
                    <li><strong>Nome do Cluster:</strong> Label descritivo (ex: "Baixo Engajamento", "Engajados")</li>
                    <li><strong>Tamanho:</strong> N√∫mero absoluto de respondentes</li>
                    <li><strong>Percentual:</strong> Propor√ß√£o em rela√ß√£o ao total</li>
                    <li><strong>Descri√ß√£o:</strong> Resumo interpretativo das caracter√≠sticas</li>
                    <li><strong>Caracter√≠sticas detalhadas:</strong> Valores modais das vari√°veis principais</li>
                </ul>
                
                <h3>Os 4 perfis t√≠picos encontrados:</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Cluster</th>
                        <th style="padding: 10px; text-align: left;">Perfil</th>
                        <th style="padding: 10px; text-align: left;">Caracter√≠sticas</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">0 üî¥</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Baixo Engajamento</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Pouco conhecimento, baixa implementa√ß√£o</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">1 üîµ</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Engajados</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Alto conhecimento, implementa√ß√£o consistente</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">2 üü¢</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Designers Conscientes</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Conhecimento moderado, foco em design</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">3 üü°</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Caso Especial</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Perfil at√≠pico, outliers</td>
                    </tr>
                </table>
                
                <h3>Import√¢ncia dos perfis:</h3>
                <p>Os perfis dos clusters transformam dados num√©ricos em <strong>insights acion√°veis</strong>:</p>
                <ul>
                    <li><strong>Segmenta√ß√£o:</strong> Permite estrat√©gias diferenciadas por grupo</li>
                    <li><strong>Personas:</strong> Base para criar personas representativas</li>
                    <li><strong>Prioriza√ß√£o:</strong> Identifica grupos que mais precisam de interven√ß√£o</li>
                    <li><strong>Comunica√ß√£o:</strong> Facilita explicar resultados para stakeholders</li>
                </ul>
                
                <h3>Como usar os perfis?</h3>
                <p>Para cada cluster identificado, desenvolva estrat√©gias espec√≠ficas:</p>
                <ul>
                    <li><strong>Baixo Engajamento:</strong> Programas de conscientiza√ß√£o e treinamento b√°sico</li>
                    <li><strong>Engajados:</strong> Certifica√ß√µes avan√ßadas e papel de lideran√ßa/mentoria</li>
                    <li><strong>Designers Conscientes:</strong> Ferramentas pr√°ticas e suporte t√©cnico</li>
                    <li><strong>Casos Especiais:</strong> Investiga√ß√£o individual para entender contexto</li>
                </ul>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    <br>
                    <strong>Interpreta√ß√£o de Clusters:</strong><br>
                    KAUFMAN, L.; ROUSSEEUW, P. J. (1990). <em>Finding Groups in Data</em>. Wiley. Cap√≠tulo 2: 
                    "Partitioning Around Medoids".<br><br>
                    
                    <strong>Persona Development:</strong><br>
                    COOPER, A. (1999). <em>The Inmates Are Running the Asylum</em>. Sams Publishing. 
                    [Metodologia de cria√ß√£o de personas]<br><br>
                    
                    <strong>Segmenta√ß√£o de Mercado:</strong><br>
                    WEDEL, M.; KAMAKURA, W. A. (2000). <em>Market Segmentation: Conceptual and Methodological Foundations</em>. 
                    2nd ed. Springer. Cap√≠tulo 6.
                </div>
            `
        },
        screePlot: {
            title: 'üìâ Scree Plot - Vari√¢ncia Explicada',
            content: `
                <h3>O que √© o Scree Plot?</h3>
                <p>O <strong>Scree Plot</strong> √© um gr√°fico de linha que mostra a <strong>vari√¢ncia explicada por cada componente principal</strong> 
                em ordem decrescente. O nome vem de "scree" (cascalho em ingl√™s), referindo-se √† apar√™ncia do gr√°fico que se assemelha a rochas caindo de uma montanha.</p>
                
                <h3>Para que serve?</h3>
                <p>O principal objetivo do Scree Plot √© ajudar a determinar <strong>quantos componentes principais devem ser retidos</strong> 
                na an√°lise. √â uma das t√©cnicas mais utilizadas para decidir a dimensionalidade √≥tima.</p>
                
                <h3>Como interpretar?</h3>
                <ul>
                    <li><strong>Eixo X:</strong> N√∫mero do componente principal (PC1, PC2, PC3, ...)</li>
                    <li><strong>Eixo Y:</strong> Propor√ß√£o da vari√¢ncia explicada (0 a 1, ou 0% a 100%)</li>
                    <li><strong>Crit√©rio do Cotovelo:</strong> Procure o ponto onde a curva faz um "cotovelo" (elbow point)</li>
                    <li><strong>Componentes antes do cotovelo:</strong> Devem ser retidos (explicam vari√¢ncia significativa)</li>
                    <li><strong>Componentes ap√≥s o cotovelo:</strong> Podem ser descartados (contribuem pouco)</li>
                </ul>
                
                <h3>Regras pr√°ticas de interpreta√ß√£o:</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Crit√©rio</th>
                        <th style="padding: 10px; text-align: left;">Descri√ß√£o</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Kaiser (eigenvalue > 1)</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Reter componentes com autovalor > 1</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Vari√¢ncia acumulada ‚â• 70%</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Reter at√© explicar 70-90% da vari√¢ncia total</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Cotovelo visual</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Reter componentes antes da "quebra" da curva</td>
                    </tr>
                </table>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// 1. Normaliza os dados<br>
const normalized = normalizeData(numericData);<br>
<br>
// 2. Calcula matriz de covari√¢ncia<br>
const covMatrix = covarianceMatrix(normalized);<br>
<br>
// 3. Decomposi√ß√£o em autovalores e autovetores<br>
const { eigenvalues, eigenvectors } = eigenDecomposition(covMatrix, 10);<br>
<br>
// 4. Calcula vari√¢ncia explicada por cada PC<br>
const totalVariance = eigenvalues.reduce((sum, val) => sum + val, 0);<br>
const explainedVariance = eigenvalues.map(val => val / totalVariance);<br>
<br>
// F√≥rmula:<br>
// Vari√¢ncia Explicada (PC_i) = Œª_i / Œ£Œª_j<br>
// onde Œª_i √© o i-√©simo autovalor
                </div>
                
                <h3>Exemplo de leitura:</h3>
                <p>Se o gr√°fico mostra:</p>
                <ul>
                    <li>PC1: 45% da vari√¢ncia</li>
                    <li>PC2: 25% da vari√¢ncia</li>
                    <li>PC3: 10% da vari√¢ncia</li>
                    <li>PC4-PC10: < 5% cada</li>
                </ul>
                <p>O "cotovelo" est√° entre PC3 e PC4, sugerindo reter <strong>3 componentes</strong> que explicam 80% da vari√¢ncia total.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    CATTELL, R. B. (1966). "The Scree Test For The Number Of Factors". 
                    <em>Multivariate Behavioral Research</em>, 1(2), 245-276. [Artigo original do m√©todo]<br><br>
                    
                    JOLLIFFE, I. T.; CADIMA, J. (2016). "Principal component analysis: a review and recent developments". 
                    <em>Philosophical Transactions of the Royal Society A</em>, 374(2065), 20150202.
                </div>
            `
        },
        cumulativeVariance: {
            title: 'üìà Vari√¢ncia Acumulada',
            content: `
                <h3>O que √© Vari√¢ncia Acumulada?</h3>
                <p>A <strong>vari√¢ncia acumulada</strong> mostra a <strong>soma progressiva</strong> da vari√¢ncia explicada 
                √† medida que mais componentes principais s√£o adicionados. √â complementar ao Scree Plot.</p>
                
                <h3>Diferen√ßa entre Vari√¢ncia Explicada e Acumulada:</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Componente</th>
                        <th style="padding: 10px; text-align: left;">Var. Explicada</th>
                        <th style="padding: 10px; text-align: left;">Var. Acumulada</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">PC1</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">45%</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">45%</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">PC2</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">25%</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">70% (45+25)</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">PC3</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">10%</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">80% (70+10)</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">PC4</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">5%</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">85% (80+5)</td>
                    </tr>
                </table>
                
                <h3>Como interpretar o gr√°fico?</h3>
                <ul>
                    <li><strong>Curva em S:</strong> O gr√°fico tipicamente forma uma curva em "S" (sigmoide)</li>
                    <li><strong>In√≠cio (crescimento r√°pido):</strong> Primeiros PCs explicam muito</li>
                    <li><strong>Plat√¥:</strong> PCs finais adicionam pouco √† vari√¢ncia total</li>
                    <li><strong>Linha de refer√™ncia 70-80%:</strong> Muitos estudos usam este limiar como adequado</li>
                </ul>
                
                <h3>Crit√©rios de decis√£o:</h3>
                <div style="background: #f0f4ff; padding: 15px; border-radius: 8px; margin: 15px 0;">
                    <p><strong>Regra dos 70%:</strong> Reter componentes at√© atingir pelo menos 70% da vari√¢ncia acumulada</p>
                    <p><strong>Regra dos 80%:</strong> An√°lises mais rigorosas podem exigir 80-90%</p>
                    <p><strong>Dom√≠nio espec√≠fico:</strong> √Åreas como finan√ßas podem exigir > 95%</p>
                </div>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// Ap√≥s calcular vari√¢ncia explicada de cada PC<br>
const explainedVariance = eigenvalues.map(val => val / totalVariance);<br>
<br>
// Calcula vari√¢ncia acumulada<br>
const cumulativeVariance = [];<br>
explainedVariance.reduce((sum, val) => {<br>
&nbsp;&nbsp;const cumSum = sum + val;<br>
&nbsp;&nbsp;cumulativeVariance.push(cumSum);<br>
&nbsp;&nbsp;return cumSum;<br>
}, 0);<br>
<br>
// F√≥rmula matem√°tica:<br>
// Var_Acum(k) = Œ£(i=1 at√© k) [Œª_i / Œ£Œª_j]<br>
// Onde k √© o n√∫mero de componentes retidos
                </div>
                
                <h3>Exemplo pr√°tico neste projeto:</h3>
                <p>Se voc√™ observar que:</p>
                <ul>
                    <li>Com <strong>2 PCs</strong>: 70% de vari√¢ncia acumulada ‚Üí Redu√ß√£o dimensional satisfat√≥ria</li>
                    <li>Com <strong>3 PCs</strong>: 80% de vari√¢ncia acumulada ‚Üí Boa representa√ß√£o</li>
                    <li>Com <strong>5 PCs</strong>: 90% de vari√¢ncia acumulada ‚Üí Excelente representa√ß√£o</li>
                </ul>
                <p>Isso significa que podemos usar apenas 2-3 componentes ao inv√©s das 19 vari√°veis originais, 
                simplificando drasticamente a an√°lise sem perder muita informa√ß√£o.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    JOLLIFFE, I. T. (2002). <em>Principal Component Analysis</em>. 2nd ed. Springer. Cap√≠tulo 6: 
                    "Choosing the Number of Components".<br><br>
                    
                    KAISER, H. F. (1960). "The Application of Electronic Computers to Factor Analysis". 
                    <em>Educational and Psychological Measurement</em>, 20(1), 141-151.
                </div>
            `
        },
        biplot: {
            title: 'üéØ Biplot - PC1 vs PC2',
            content: `
                <h3>O que √© um Biplot?</h3>
                <p>O <strong>Biplot</strong> √© uma representa√ß√£o gr√°fica que combina duas visualiza√ß√µes em um √∫nico gr√°fico:</p>
                <ol>
                    <li><strong>Observa√ß√µes (pontos):</strong> Cada ponto representa um respondente projetado em PC1 e PC2</li>
                    <li><strong>Vari√°veis (vetores):</strong> Setas representam as vari√°veis originais e suas rela√ß√µes com os PCs</li>
                </ol>
                
                <h3>Por que PC1 vs PC2?</h3>
                <p>Estes s√£o os <strong>dois primeiros componentes principais</strong>, que capturam a maior parte da vari√¢ncia. 
                Visualizar em 2D permite entender a estrutura dos dados sem sobrecarregar cognitivamente.</p>
                
                <h3>Como interpretar os elementos?</h3>
                
                <h4>üîµ Pontos (Observa√ß√µes):</h4>
                <ul>
                    <li><strong>Proximidade:</strong> Pontos pr√≥ximos t√™m caracter√≠sticas similares</li>
                    <li><strong>Dist√¢ncia:</strong> Pontos distantes s√£o dissimilares</li>
                    <li><strong>Agrupamentos:</strong> Clusters naturais indicam grupos distintos</li>
                    <li><strong>Outliers:</strong> Pontos isolados s√£o casos at√≠picos</li>
                </ul>
                
                <h4>‚û°Ô∏è Setas (Vari√°veis):</h4>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Caracter√≠stica</th>
                        <th style="padding: 10px; text-align: left;">Interpreta√ß√£o</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Comprimento da seta</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Quanto maior, mais importante a vari√°vel nos 2 PCs</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Dire√ß√£o da seta</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Mostra em qual dire√ß√£o a vari√°vel aumenta</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>√Çngulo pequeno (< 30¬∞)</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Vari√°veis correlacionadas positivamente</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>√Çngulo ~90¬∞</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Vari√°veis n√£o correlacionadas</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>√Çngulo ~180¬∞</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Vari√°veis correlacionadas negativamente</td>
                    </tr>
                </table>
                
                <h3>Combinando pontos e setas:</h3>
                <p>Se um ponto est√° na <strong>dire√ß√£o de uma seta</strong>, isso indica que aquele respondente tem 
                <strong>valores altos</strong> naquela vari√°vel. Pontos na dire√ß√£o oposta t√™m valores baixos.</p>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// 1. Projetar observa√ß√µes nos componentes principais<br>
const projectedData = projectData(normalized, eigenvectors);<br>
<br>
// Cada observa√ß√£o i tem coordenadas:<br>
// PC1_i = Œ£(j=1 at√© p) X_ij * eigenvector1_j<br>
// PC2_i = Œ£(j=1 at√© p) X_ij * eigenvector2_j<br>
<br>
// 2. Calcular loadings (pesos das vari√°veis)<br>
const loadings = eigenvectors; // Autovetores s√£o os loadings<br>
<br>
// 3. Plotar:<br>
// - Pontos: (PC1_i, PC2_i) para cada observa√ß√£o i<br>
// - Setas: (loading1_j * escala, loading2_j * escala) para cada vari√°vel j<br>
<br>
// Implementa√ß√£o da proje√ß√£o:<br>
projectData(data, eigenvectors) {<br>
&nbsp;&nbsp;return eigenvectors.map(evec => <br>
&nbsp;&nbsp;&nbsp;&nbsp;data.map(row => <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;row.reduce((sum, val, idx) => sum + val * evec[idx], 0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;);<br>
}
                </div>
                
                <h3>Limita√ß√£o importante:</h3>
                <p>‚ö†Ô∏è O biplot mostra apenas <strong>2 dimens√µes</strong> (PC1 e PC2). Se estes dois componentes explicam 
                apenas 50% da vari√¢ncia, h√° 50% de informa√ß√£o em outras dimens√µes que n√£o est√° vis√≠vel no gr√°fico.</p>
                
                <h3>Exemplo de insights do Biplot:</h3>
                <ul>
                    <li>Se vari√°veis relacionadas a WCAG apontam para a direita e h√° um cluster √† direita, 
                    esse grupo tem alto conhecimento em WCAG</li>
                    <li>Se h√° dois clusters bem separados na vertical, PC2 est√° capturando uma distin√ß√£o importante</li>
                    <li>Se todas as setas apontam na mesma dire√ß√£o, as vari√°veis est√£o altamente correlacionadas</li>
                </ul>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br><br>
                    
                    <strong>Artigo Original do Biplot:</strong><br>
                    GABRIEL, K. R. (1971). "The biplot graphic display of matrices with application to principal component analysis". 
                    <em>Biometrika</em>, 58(3), 453-467.<br><br>
                    
                    <strong>Interpreta√ß√£o e Uso:</strong><br>
                    GREENACRE, M. (2010). <em>Biplots in Practice</em>. Fundaci√≥n BBVA. [Guia pr√°tico completo]<br><br>
                    
                    <strong>PCA e Visualiza√ß√£o:</strong><br>
                    JOLLIFFE, I. T.; CADIMA, J. (2016). "Principal component analysis: a review and recent developments". 
                    <em>Philosophical Transactions of the Royal Society A</em>, 374(2065).
                </div>
            `
        },
        pcaSummary: {
            title: 'üìä Resumo da An√°lise PCA',
            content: `
                <h3>O que √© o Resumo PCA?</h3>
                <p>Esta se√ß√£o apresenta uma <strong>tabela consolidada</strong> com as principais m√©tricas de cada componente principal, 
                facilitando a interpreta√ß√£o quantitativa da an√°lise.</p>
                
                <h3>Informa√ß√µes apresentadas:</h3>
                <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
                    <tr style="background: #f0f4ff;">
                        <th style="padding: 10px; text-align: left;">Coluna</th>
                        <th style="padding: 10px; text-align: left;">Descri√ß√£o</th>
                        <th style="padding: 10px; text-align: left;">Como Interpretar</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Componente</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">PC1, PC2, PC3...</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Ordenados por import√¢ncia (maior ‚Üí menor)</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>Autovalor (Œª)</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Vari√¢ncia capturada pelo PC</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Œª > 1: componente importante (crit√©rio Kaiser)</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>% Vari√¢ncia</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">% explicado por este PC</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Quanto maior, mais importante o componente</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;"><strong>% Acumulada</strong></td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">Soma progressiva da vari√¢ncia</td>
                        <td style="padding: 10px; border-top: 1px solid #e5e7eb;">‚â• 70-80%: boa representa√ß√£o dos dados</td>
                    </tr>
                </table>
                
                <h3>Exemplo de leitura da tabela:</h3>
                <div style="background: #f0f4ff; padding: 15px; border-radius: 8px; margin: 15px 0;">
                    <table style="width: 100%; border-collapse: collapse;">
                        <tr style="background: #667eea; color: white;">
                            <th style="padding: 8px;">PC</th>
                            <th style="padding: 8px;">Autovalor</th>
                            <th style="padding: 8px;">% Var</th>
                            <th style="padding: 8px;">% Acum</th>
                        </tr>
                        <tr style="background: white;">
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">PC1</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">8.5</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">45%</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">45%</td>
                        </tr>
                        <tr style="background: #f9fafb;">
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">PC2</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">4.7</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">25%</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">70%</td>
                        </tr>
                        <tr style="background: white;">
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">PC3</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">1.9</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">10%</td>
                            <td style="padding: 8px; border: 1px solid #e5e7eb;">80%</td>
                        </tr>
                    </table>
                    <p style="margin-top: 10px;"><strong>Interpreta√ß√£o:</strong></p>
                    <ul style="margin: 5px 0;">
                        <li>‚úÖ PC1, PC2, PC3 t√™m autovalor > 1 (crit√©rio Kaiser)</li>
                        <li>‚úÖ Com 3 PCs atingimos 80% de vari√¢ncia acumulada</li>
                        <li>‚úÖ Podemos reduzir de 19 vari√°veis para 3 componentes</li>
                    </ul>
                </div>
                
                <h3>Como √© calculado neste c√≥digo?</h3>
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// Ap√≥s performPCA(), extrair os resultados<br>
const pca = analyzer.pcaResults;<br>
<br>
// Para cada componente principal i:<br>
const summary = pca.eigenvalues.map((eigenvalue, idx) => ({<br>
&nbsp;&nbsp;component: 'PC' + (idx + 1),<br>
&nbsp;&nbsp;eigenvalue: eigenvalue.toFixed(3),<br>
&nbsp;&nbsp;variancePercent: (pca.explainedVariance[idx] * 100).toFixed(2) + '%',<br>
&nbsp;&nbsp;cumulativePercent: (pca.cumulativeVariance[idx] * 100).toFixed(2) + '%'<br>
}));<br>
<br>
// Renderizar tabela HTML com as informa√ß√µes
                </div>
                
                <h3>Como usar este resumo na pr√°tica?</h3>
                <ol>
                    <li><strong>Identificar componentes importantes:</strong> Use crit√©rio Kaiser (Œª > 1)</li>
                    <li><strong>Decidir quantos PCs reter:</strong> Quando % Acumulada ‚â• 70-80%</li>
                    <li><strong>Reportar em artigos:</strong> "Os primeiros 3 componentes explicaram 80% da vari√¢ncia total (Œª‚ÇÅ=8.5, Œª‚ÇÇ=4.7, Œª‚ÇÉ=1.9)"</li>
                    <li><strong>Simplificar an√°lises subsequentes:</strong> Use apenas os PCs retidos em clustering, regress√£o, etc.</li>
                </ol>
                
                <h3>Benef√≠cios da redu√ß√£o dimensional:</h3>
                <ul>
                    <li>‚úÖ <strong>Visualiza√ß√£o:</strong> 3 PCs podem ser plotados em 3D, 19 vari√°veis n√£o</li>
                    <li>‚úÖ <strong>Performance:</strong> Algoritmos de ML rodam mais r√°pido com menos dimens√µes</li>
                    <li>‚úÖ <strong>Interpretabilidade:</strong> Mais f√°cil entender 3 componentes que 19 vari√°veis</li>
                    <li>‚úÖ <strong>Multicolinearidade:</strong> PCs s√£o ortogonais (n√£o correlacionados)</li>
                    <li>‚úÖ <strong>Ru√≠do:</strong> Componentes finais capturam ru√≠do, que √© descartado</li>
                </ul>
                
                <h3>Aplica√ß√µes pr√°ticas neste projeto:</h3>
                <p>Ap√≥s o PCA, os componentes retidos s√£o usados para:</p>
                <ul>
                    <li><strong>Clustering:</strong> K-Means e Hier√°rquico s√£o executados no espa√ßo PCA reduzido</li>
                    <li><strong>Visualiza√ß√£o:</strong> Biplot mostra dados em 2D (PC1 vs PC2)</li>
                    <li><strong>Correla√ß√£o:</strong> An√°lise de correla√ß√£o entre PCs principais</li>
                </ul>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias:</strong><br>
                    KAISER, H. F. (1960). "The Application of Electronic Computers to Factor Analysis". 
                    <em>Educational and Psychological Measurement</em>, 20(1), 141-151. [Crit√©rio Kaiser: Œª > 1]<br><br>
                    
                    JOLLIFFE, I. T. (2002). <em>Principal Component Analysis</em>. 2nd ed. Springer. 
                    Cap√≠tulo 6: "Choosing the Number of Components".<br><br>
                    
                    ABDI, H.; WILLIAMS, L. J. (2010). "Principal component analysis". 
                    <em>Wiley Interdisciplinary Reviews: Computational Statistics</em>, 2(4), 433-459.
                </div>
            `
        },
        elbow: {
            title: 'üìê M√©todo do Cotovelo (Elbow Method)',
            content: `
                <h3>O que √©?</h3>
                <p>O <strong>M√©todo do Cotovelo</strong> √© uma t√©cnica heur√≠stica para determinar o <strong>n√∫mero ideal de clusters</strong> 
                (k) em an√°lises de clustering. O nome vem do formato do gr√°fico, que se assemelha a um bra√ßo dobrado.</p>
                
                <h3>Como funciona?</h3>
                <p>O m√©todo calcula a <strong>in√©rcia</strong> (tamb√©m chamada de <em>within-cluster sum of squares</em> - WCSS) 
                para diferentes valores de k:</p>
                
                <ol>
                    <li><strong>Para k = 2 at√© maxK (10):</strong>
                        <ul>
                            <li>Executa o algoritmo K-Means com k clusters</li>
                            <li>Calcula a in√©rcia total</li>
                        </ul>
                    </li>
                    <li><strong>Plota in√©rcia vs. n√∫mero de clusters</strong></li>
                    <li><strong>Identifica o "cotovelo"</strong> - ponto onde a taxa de redu√ß√£o da in√©rcia diminui drasticamente</li>
                </ol>
                
                <h3>F√≥rmula da In√©rcia (WCSS)</h3>
                <p>A in√©rcia mede a <strong>compacta√ß√£o dos clusters</strong> atrav√©s da soma das dist√¢ncias quadradas 
                de cada ponto ao centroide de seu cluster:</p>
                
                <div style="background: #f0f4ff; padding: 15px; border-radius: 8px; margin: 15px 0;">
                    <code style="font-size: 1.1em;">
                        In√©rcia = Œ£<sub>i=1</sub><sup>n</sup> ||x<sub>i</sub> - Œº<sub>c(i)</sub>||¬≤
                    </code>
                    <p style="margin-top: 10px; font-size: 0.9em;">
                        Onde:<br>
                        ‚Ä¢ x<sub>i</sub> = ponto de dados i<br>
                        ‚Ä¢ Œº<sub>c(i)</sub> = centroide do cluster c ao qual o ponto i pertence<br>
                        ‚Ä¢ ||¬∑|| = dist√¢ncia Euclidiana<br>
                        ‚Ä¢ n = n√∫mero total de pontos
                    </p>
                </div>
                
                <h3>Como foi calculado neste c√≥digo?</h3>
                <p><strong>Implementa√ß√£o JavaScript:</strong></p>
                
                <div style="background: #2d3748; color: #e2e8f0; padding: 15px; border-radius: 8px; margin: 15px 0; font-family: monospace; font-size: 0.9em;">
// 1. M√©todo principal (analyzer.js)<br>
elbowMethod(maxK = 10) {<br>
&nbsp;&nbsp;const inertias = [];<br>
&nbsp;&nbsp;const normalized = this.normalizeData(this.numericData);<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;// Testa k de 2 at√© 10<br>
&nbsp;&nbsp;for (let k = 2; k <= maxK; k++) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;const result = this.performKMeansForK(normalized, k);<br>
&nbsp;&nbsp;&nbsp;&nbsp;inertias.push({ k, inertia: result.inertia });<br>
&nbsp;&nbsp;}<br>
&nbsp;&nbsp;<br>
&nbsp;&nbsp;return inertias; // [{k:2, inertia:X}, {k:3, inertia:Y}, ...]<br>
}<br>
<br>
// 2. C√°lculo da in√©rcia<br>
calculateInertia(data, clusters, centroids) {<br>
&nbsp;&nbsp;return data.reduce((sum, point, idx) => {<br>
&nbsp;&nbsp;&nbsp;&nbsp;const cluster = clusters[idx];<br>
&nbsp;&nbsp;&nbsp;&nbsp;const centroid = centroids[cluster];<br>
&nbsp;&nbsp;&nbsp;&nbsp;// Soma das dist√¢ncias quadradas<br>
&nbsp;&nbsp;&nbsp;&nbsp;return sum + Math.pow(this.euclideanDistance(point, centroid), 2);<br>
&nbsp;&nbsp;}, 0);<br>
}
                </div>
                
                <h3>Como interpretar o gr√°fico?</h3>
                <ul>
                    <li><strong>Eixo X:</strong> N√∫mero de clusters (k)</li>
                    <li><strong>Eixo Y:</strong> In√©rcia (WCSS) - menor √© melhor</li>
                    <li><strong>Tend√™ncia:</strong> In√©rcia sempre diminui com mais clusters</li>
                    <li><strong>Ponto ideal:</strong> Onde a curva "dobra" (cotovelo)
                        <ul>
                            <li>Adicionar mais clusters n√£o reduz significativamente a in√©rcia</li>
                            <li>Equil√≠brio entre simplicidade e qualidade</li>
                        </ul>
                    </li>
                </ul>
                
                <h3>Exemplo de interpreta√ß√£o:</h3>
                <p>Se o gr√°fico mostra uma queda acentuada at√© k=4 e depois estabiliza, isso indica que 
                <strong>4 clusters</strong> √© a escolha ideal. Usar k=5 ou k=6 n√£o traria ganho significativo 
                na compacta√ß√£o dos clusters, apenas aumentaria a complexidade.</p>
                
                <h3>Limita√ß√µes</h3>
                <ul>
                    <li>Nem sempre h√° um "cotovelo" claro e √≥bvio</li>
                    <li>√â um m√©todo subjetivo - requer an√°lise visual</li>
                    <li>Deve ser complementado com outras m√©tricas (Silhouette Score, Gap Statistic)</li>
                    <li>Sens√≠vel √† normaliza√ß√£o dos dados</li>
                </ul>
                
                <h3>Neste projeto:</h3>
                <p>Os dados foram <strong>normalizados</strong> (StandardScaler) antes do c√°lculo para garantir 
                que todas as vari√°veis tenham peso igual. O algoritmo K-Means foi executado para k de 2 at√© 10, 
                e a in√©rcia foi calculada somando as dist√¢ncias Euclidianas quadradas de cada ponto ao seu centroide.</p>
                
                <div class="reference">
                    <strong>üìö Refer√™ncias Principais:</strong><br>
                    <br>
                    <strong>M√©todo do Cotovelo:</strong><br>
                    THORNDIKE, R. L. (1953). "Who belongs in the family?". <em>Psychometrika</em>, 18(4), 267-276. 
                    [Origem do m√©todo do cotovelo]<br><br>
                    
                    <strong>K-Means e WCSS:</strong><br>
                    MACQUEEN, J. (1967). "Some methods for classification and analysis of multivariate observations". 
                    <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</em>, 
                    1(14), 281-297. [K-Means original]<br><br>
                    
                    <strong>Aplica√ß√µes modernas:</strong><br>
                    JAIN, A. K. (2010). "Data Clustering: 50 Years Beyond K-means". <em>Pattern Recognition Letters</em>, 
                    31(8), 651-666. [Revis√£o completa incluindo m√©todo do cotovelo]<br><br>
                    
                    <strong>Sele√ß√£o do n√∫mero de clusters:</strong><br>
                    KODINARIYA, T. M.; MAKWANA, P. R. (2013). "Review on determining number of Cluster in K-Means Clustering". 
                    <em>International Journal of Advance Research in Computer Science and Management Studies</em>, 1(6), 90-95.
                </div>
            `
        }
    };
    
    const info = infoContent[section];
    if (info) {
        modalTitle.textContent = info.title;
        modalBody.innerHTML = info.content;
        modal.style.display = 'block';
    }
}

function closeInfoModal() {
    document.getElementById('infoModal').style.display = 'none';
}

// Fechar modal ao clicar fora
window.onclick = function(event) {
    const modal = document.getElementById('infoModal');
    if (event.target === modal) {
        modal.style.display = 'none';
    }
};

// Fechar modal com ESC
document.addEventListener('keydown', function(event) {
    if (event.key === 'Escape') {
        closeInfoModal();
    }
});

// Log inicial
console.log('üöÄ Aplica√ß√£o de An√°lise Multivariada carregada!');
console.log('üìù Fa√ßa upload de um arquivo CSV para come√ßar a an√°lise');
